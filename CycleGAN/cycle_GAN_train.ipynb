{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "B8DM4RdMsjk8",
   "metadata": {
    "id": "B8DM4RdMsjk8"
   },
   "source": [
    "# Import libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "a4491e7b",
   "metadata": {
    "id": "a4491e7b"
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "\n",
    "from torchvision.utils import save_image\n",
    "\n",
    "from discriminator import Discriminator\n",
    "from generator import Generator\n",
    "from dataset import MapDataset\n",
    "from utils import save_checkpoint, load_checkpoint\n",
    "import config\n",
    "\n",
    "import sys\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb2bd83b",
   "metadata": {
    "id": "bb2bd83b"
   },
   "source": [
    "# Train function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66a521d7",
   "metadata": {
    "id": "66a521d7"
   },
   "outputs": [],
   "source": [
    "def train_function(\n",
    "          Discriminator_Map,\n",
    "          Discriminator_Aerial,\n",
    "          Generator_Aerial,\n",
    "          Generator_Map,\n",
    "          dataloader,\n",
    "          optim_discriminator,\n",
    "          optim_generator,\n",
    "          L1_loss,\n",
    "          MSE_loss,\n",
    "          generator_scaler,\n",
    "          discriminator_scaler,\n",
    "          epoch,\n",
    "      ):\n",
    "    loop = tqdm(dataloader, leave=True)\n",
    "\n",
    "    for index, (map, aerial_photo) in enumerate(loop):\n",
    "      map = map.to(config.DEVICE)\n",
    "      aerial_photo = aerial_photo.to(config.DEVICE)\n",
    "\n",
    "      # Discriminators training\n",
    "      with torch.cuda.amp.autocast():\n",
    "        # Aerial discriminator train\n",
    "        aerial_fake = Generator_Aerial(map)\n",
    "\n",
    "        disc_aerial_real = Discriminator_Aerial(aerial_photo)\n",
    "        disc_aerial_fake = Discriminator_Aerial(aerial_fake.detach())\n",
    "\n",
    "        disc_aerial_real_loss = MSE_loss(disc_aerial_real, torch.ones_like(disc_aerial_real))\n",
    "        disc_aerial_fake_loss = MSE_loss(disc_aerial_fake, torch.zeros_like(disc_aerial_fake))\n",
    "\n",
    "        disc_aerial_loss = disc_aerial_real_loss + disc_aerial_fake_loss\n",
    "\n",
    "        # Map discriminator train\n",
    "        map_fake = Generator_Map(aerial_photo)\n",
    "\n",
    "        disc_map_real = Discriminator_Map(map)\n",
    "        disc_map_fake = Discriminator_Map(map_fake.detach())\n",
    "\n",
    "        disc_map_real_loss = MSE_loss(disc_map_real, torch.ones_like(disc_map_real))\n",
    "        disc_map_fake_loss = MSE_loss(disc_map_fake, torch.zeros_like(disc_map_fake))\n",
    "\n",
    "        disc_map_loss = disc_map_real_loss + disc_map_fake_loss\n",
    "\n",
    "        # Put loss together\n",
    "        Discriminator_loss = (disc_aerial_loss + disc_map_loss)/2\n",
    "\n",
    "      optim_discriminator.zero_grad()\n",
    "      discriminator_scaler.scale(Discriminator_loss).backward()\n",
    "      discriminator_scaler.step(optim_discriminator)\n",
    "      discriminator_scaler.update()\n",
    "\n",
    "      # Generators training\n",
    "      with torch.cuda.amp.autocast():\n",
    "        # Adversarial loss for generators\n",
    "        disc_aerial_fake = Discriminator_Aerial(aerial_fake)\n",
    "        disc_map_fake = Discriminator_Map(map_fake)\n",
    "\n",
    "        Generator_loss_aerial = MSE_loss(disc_aerial_fake, torch.ones_like(disc_aerial_fake))\n",
    "        Generator_loss_map = MSE_loss(disc_map_fake, torch.ones_like(disc_map_fake))\n",
    "\n",
    "        #Cycle loss\n",
    "        cycle_map = Generator_Map(aerial_fake)\n",
    "        cycle_aerial = Generator_Aerial(map_fake)\n",
    "\n",
    "        cycle_map_loss = L1_loss(map, cycle_map)\n",
    "        cycle_aerial_loss = L1_loss(aerial_photo, cycle_aerial)\n",
    "\n",
    "        # Put loss together\n",
    "        Generator_loss = (\n",
    "            Generator_loss_map\n",
    "            + Generator_loss_aerial\n",
    "            + cycle_map_loss * config.LAMBDA_CYCLE\n",
    "            + cycle_aerial_loss * config.LAMBDA_CYCLE\n",
    "        )\n",
    "\n",
    "      optim_generator.zero_grad()\n",
    "      generator_scaler.scale(Generator_loss).backward()\n",
    "      generator_scaler.step(optim_generator)\n",
    "      generator_scaler.update()\n",
    "\n",
    "    print(f\"Epoch {epoch} | Generator loss: {Generator_loss} | Discriminator loss: {Discriminator_loss}\")\n",
    "    if epoch % 5 == 0:\n",
    "      cycle_first = torch.cat((map, aerial_fake * 0.5 + 0.5, cycle_map), dim=2)\n",
    "      save_image(cycle_first, f\"saved_images/cycle_first_{epoch}.png\")\n",
    "\n",
    "      cycle_second = torch.cat((aerial_photo, map_fake * 0.5 + 0.5, cycle_aerial), dim=2)\n",
    "      save_image(cycle_second, f\"saved_images/cycle_second_{epoch}.png\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a21c4681",
   "metadata": {
    "id": "a21c4681"
   },
   "source": [
    "# Train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "00c47fec",
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 654
    },
    "id": "00c47fec",
    "outputId": "de9bbae5-0626-4c40-a236-370c67a33f3a"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "<ipython-input-22-7e58e41fc827>:54: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  generator_scaler = torch.cuda.amp.GradScaler()\n",
      "<ipython-input-22-7e58e41fc827>:55: FutureWarning: `torch.cuda.amp.GradScaler(args...)` is deprecated. Please use `torch.amp.GradScaler('cuda', args...)` instead.\n",
      "  discriminator_scaler = torch.cuda.amp.GradScaler()\n",
      "  0%|          | 0/1096 [00:00<?, ?it/s]<ipython-input-21-baeb14d21616>:22: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "<ipython-input-21-baeb14d21616>:54: FutureWarning: `torch.cuda.amp.autocast(args...)` is deprecated. Please use `torch.amp.autocast('cuda', args...)` instead.\n",
      "  with torch.cuda.amp.autocast():\n",
      "100%|██████████| 1096/1096 [03:07<00:00,  5.85it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0 | Generator loss: 3.988966464996338 | Discriminator loss: 0.3280376195907593\n",
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n",
      "=> Saving checkpoint\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  3%|▎         | 36/1096 [00:06<03:11,  5.54it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-22-7e58e41fc827>\u001b[0m in \u001b[0;36m<cell line: 58>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[0;31m# Train loop\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mNUM_EPOCHS\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m   train_function(\n\u001b[0m\u001b[1;32m     60\u001b[0m       \u001b[0mDiscriminator_Map\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m       \u001b[0mDiscriminator_Aerial\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-21-baeb14d21616>\u001b[0m in \u001b[0;36mtrain_function\u001b[0;34m(Discriminator_Map, Discriminator_Aerial, Generator_Aerial, Generator_Map, dataloader, optim_discriminator, optim_generator, L1_loss, MSE_loss, generator_scaler, discriminator_scaler, epoch)\u001b[0m\n\u001b[1;32m     86\u001b[0m       \u001b[0moptim_generator\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     87\u001b[0m       \u001b[0mgenerator_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscale\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGenerator_loss\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 88\u001b[0;31m       \u001b[0mgenerator_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptim_generator\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     89\u001b[0m       \u001b[0mgenerator_scaler\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     90\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36mstep\u001b[0;34m(self, optimizer, *args, **kwargs)\u001b[0m\n\u001b[1;32m    455\u001b[0m         ), \"No inf checks were recorded for this optimizer.\"\n\u001b[1;32m    456\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 457\u001b[0;31m         \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_maybe_opt_step\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    458\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    459\u001b[0m         \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"stage\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mOptState\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mSTEPPED\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36m_maybe_opt_step\u001b[0;34m(self, optimizer, optimizer_state, *args, **kwargs)\u001b[0m\n\u001b[1;32m    349\u001b[0m     ) -> Optional[float]:\n\u001b[1;32m    350\u001b[0m         \u001b[0mretval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/amp/grad_scaler.py\u001b[0m in \u001b[0;36m<genexpr>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    349\u001b[0m     ) -> Optional[float]:\n\u001b[1;32m    350\u001b[0m         \u001b[0mretval\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mOptional\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 351\u001b[0;31m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0msum\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mv\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mitem\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mv\u001b[0m \u001b[0;32min\u001b[0m \u001b[0moptimizer_state\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"found_inf_per_device\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    352\u001b[0m             \u001b[0mretval\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    353\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mretval\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# Discriminators initialization\n",
    "Discriminator_Map = Discriminator(in_channels=3).to(config.DEVICE)\n",
    "Discriminator_Aerial = Discriminator(in_channels=3).to(config.DEVICE)\n",
    "\n",
    "# Generators initialization\n",
    "Generator_Map = Generator(img_channels=3, num_residuals=9).to(config.DEVICE)\n",
    "Generator_Aerial = Generator(img_channels=3, num_residuals=9).to(config.DEVICE)\n",
    "\n",
    "# Optimizators initialization\n",
    "optim_discriminator = optim.Adam(\n",
    "    list(Discriminator_Map.parameters()) + list(Discriminator_Aerial.parameters()),\n",
    "    lr = config.LEARNING_RATE,\n",
    "    betas = (0.5, 0.999),\n",
    ")\n",
    "\n",
    "optim_generator = optim.Adam(\n",
    "    list(Generator_Map.parameters()) + list(Generator_Aerial.parameters()),\n",
    "    lr = config.LEARNING_RATE,\n",
    "    betas = (0.5, 0.999),\n",
    ")\n",
    "\n",
    "# Loss funtions initialization\n",
    "L1_loss = nn.L1Loss()\n",
    "MSE_loss = nn.MSELoss()\n",
    "\n",
    "if config.LOAD_MODEL:\n",
    "  load_checkpoint(\n",
    "      config.CHECKPOINT_GEN_M, Generator_Map, optim_generator ,config.LEARNING_RATE,\n",
    "  )\n",
    "  load_checkpoint(\n",
    "      config.CHECKPOINT_GEN_A, Generator_Aerial, optim_generator ,config.LEARNING_RATE,\n",
    "  )\n",
    "  load_checkpoint(\n",
    "      config.CHECKPOINT_CRITIC_M, Discriminator_Map, optim_discriminator ,config.LEARNING_RATE,\n",
    "  )\n",
    "  load_checkpoint(\n",
    "      config.CHECKPOINT_CRITIC_A, Discriminator_Aerial, optim_discriminator ,config.LEARNING_RATE,\n",
    "  )\n",
    "\n",
    "# Dataset and Dataloader initialization\n",
    "dataset = MapDataset(\n",
    "    root_map = config.TRAIN_DIR + \"/trainB\", root_aerial = config.TRAIN_DIR + \"/trainA\", transform=config.transforms\n",
    ")\n",
    "\n",
    "dataloader = DataLoader(\n",
    "    dataset,\n",
    "    batch_size=config.BATCH_SIZE,\n",
    "    shuffle=True,\n",
    "    num_workers=config.NUM_WORKERS,\n",
    "    pin_memory=True,\n",
    ")\n",
    "\n",
    "# Scalers initialization\n",
    "generator_scaler = torch.cuda.amp.GradScaler()\n",
    "discriminator_scaler = torch.cuda.amp.GradScaler()\n",
    "\n",
    "# Train loop\n",
    "for epoch in range(config.NUM_EPOCHS):\n",
    "  train_function(\n",
    "      Discriminator_Map,\n",
    "      Discriminator_Aerial,\n",
    "      Generator_Aerial,\n",
    "      Generator_Map,\n",
    "      dataloader,\n",
    "      optim_discriminator,\n",
    "      optim_generator,\n",
    "      L1_loss,\n",
    "      MSE_loss,\n",
    "      generator_scaler,\n",
    "      discriminator_scaler,\n",
    "      epoch,\n",
    "  )\n",
    "\n",
    "  if config.SAVE_MODEL:\n",
    "    save_checkpoint(Generator_Map, optim_generator, file_name=config.CHECKPOINT_GEN_M)\n",
    "    save_checkpoint(Generator_Aerial, optim_generator, file_name=config.CHECKPOINT_GEN_A)\n",
    "    save_checkpoint(Discriminator_Map, optim_discriminator, file_name=config.CHECKPOINT_CRITIC_M)\n",
    "    save_checkpoint(Discriminator_Aerial, optim_discriminator, file_name=config.CHECKPOINT_CRITIC_A)\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
